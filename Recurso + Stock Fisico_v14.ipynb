{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd56aa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import win32com.client as win32\n",
    "import os\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7965b66d",
   "metadata": {},
   "source": [
    "## Ingresar nombre archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5234b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre archivos\n",
    "Stock_Fisico = 'STOCK FISICO 15-09.xlsx'\n",
    "Recurso = 'RECURSO 15-09.xlsx'\n",
    "PDI = 'PDI 15-09.xlsx'\n",
    "PDO = 'PDO 15-09.xlsx'\n",
    "Archivo_Dia_Anterior = '2023-09-14 ON HAND COMPLETO.xlsb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d134c",
   "metadata": {},
   "source": [
    "## Cargar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af875718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock Fisico\n",
    "df1 = pd.read_excel(Stock_Fisico ,  dtype =\"string\",\n",
    "                    usecols = ['Tipo almacén','Ubicación','UMp sup.','UMp superior','Unidad manipulación','Documento',\n",
    "                              'Número de posición','Tipo de documento','Producto','Descripción de producto','Ctd.',\n",
    "                              'Propietario','Persona autorizada a disponer','Fecha EM','Hora EM','Tipo de stocks'])\n",
    "\n",
    "# Al cargar la data, python lee las comas como puntos, por lo tanto aplicamos la funcion replace para mantenerlas como ','\n",
    "df1['Ctd.'] = df1['Ctd.'].str.replace(\".\",\",\", regex = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8333e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurso\n",
    "df2 = pd.read_excel(Recurso, dtype = \"string\", \n",
    "                    usecols = ['UMp sup.','UMp superior','Unidad manipulación','Documento','Número de posición',\n",
    "                              'Tipo de documento','Producto','Descripción de producto','Ctd.','Propietario',\n",
    "                              'Persona autorizada a disponer','Fecha EM','Hora EM','Tipo de stocks'])\n",
    "\n",
    "# Insertamos las columnas 'Ubicación' y 'Tipo almacén' para que nos cuadre Stock Fisico y Recurso al momento de concatenarlos\n",
    "df2.insert(loc = 0, column = 'Ubicación', value = 'RECURSO')\n",
    "df2.insert(loc = 0, column = 'Tipo almacén', value = 'RECURSO')\n",
    "\n",
    "# Nos aseguramos que las dos columnas que agregamos tengan formato texto (string)\n",
    "df2['Ubicación'] = df2['Ubicación'].astype('string')\n",
    "df2['Tipo almacén'] = df2['Tipo almacén'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec341440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alinear columnas ambos archivos\n",
    "columns_names = ['Tipo almacén', 'Ubicación', 'UMp sup.', 'UMp superior','Unidad manipulación', 'Documento', \n",
    "                'Número de posición','Tipo de documento', 'Producto', 'Descripción de producto', 'Ctd.','Propietario', \n",
    "                'Persona autorizada a disponer', 'Fecha EM', 'Hora EM','Tipo de stocks']\n",
    "\n",
    "df1 = df1.reindex(columns = columns_names)\n",
    "df2 = df2.reindex(columns = columns_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9275a408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planilla de Ubicaciones-Tipo de Proceso, utilizando el On Hand completo del día anterior.\n",
    "df_base2 = df3 = pd.read_excel(Archivo_Dia_Anterior , sheet_name = 'BASE 2', dtype = \"string\")\n",
    "df3 = df_base2.loc[: , ['Ubicación','TIPO DE PROCESO']]\n",
    "\n",
    "# Eliminamos los duplicados de la columna 'Ubicación' para no tener registros adicionales al momento de aplicar la función Join.\n",
    "df3.drop_duplicates('Ubicación', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ad2554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDI y PDO\n",
    "df4 = pd.read_excel(PDI , usecols = ['Documento','Número de posición','Orden de servicio','Operación de orden de servicio'], \n",
    "                    dtype = \"string\")\n",
    "df5 = pd.read_excel(PDO , usecols = ['Documento','Número de posición','Orden de servicio','Operación de orden de servicio'],\n",
    "                    dtype = \"string\")\n",
    "\n",
    "# Reordenamos Columnas\n",
    "columns_names_di = ['Documento','Número de posición','Orden de servicio','Operación de orden de servicio']\n",
    "df4 = df4.reindex(columns = columns_names_di)\n",
    "df5 = df5.reindex(columns = columns_names_di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2a9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OnHand completo del día anterior, necesitamos las columnas CONCAT, OS y OP\n",
    "df10 = pd.read_excel(Archivo_Dia_Anterior , sheet_name = 'BASE 1', engine = 'pyxlsb',\n",
    "                     usecols = ['Unidad manipulación', 'Producto', 'Ctd.','OS','OP'], dtype =\"string\")\n",
    "\n",
    "df10.loc[pd.isna(df10['Unidad manipulación']), 'Unidad manipulación'] = ''\n",
    "df10['CONCAT'] = df10['Unidad manipulación'] + df10['Producto'] + df10['Ctd.']\n",
    "df10.drop(labels = ['Unidad manipulación', 'Producto', 'Ctd.'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab35cb",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff358f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar Stock Fisico y Recurso\n",
    "df6 = pd.concat([df1,df2], axis = 0)\n",
    "df6.reset_index(inplace = True)\n",
    "df6.drop(labels = 'index', axis = 1, inplace = True)\n",
    "df6['Identificador Unico'] = df6.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e1ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busqueda TIPO DE PROCESO según la ubicación\n",
    "df3.set_index('Ubicación', inplace = True)\n",
    "df6.set_index('Ubicación', inplace = True)\n",
    "df6 = df6.join(df3, how = 'left')\n",
    "df6.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "829f64b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nuevas columnas CONCAT y D+I\n",
    "df6.loc[pd.isna(df6['Unidad manipulación']), 'Unidad manipulación'] = ''\n",
    "df6['CONCAT'] = df6['Unidad manipulación'] + df6['Producto'] + df6['Ctd.']\n",
    "df6['D+I'] = df6['Documento'] + df6['Número de posición']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "289f5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Concatenar PDI y PDO  y crear D+I para el cruce\n",
    "df7 = pd.concat([df4,df5])\n",
    "df7['D+I'] = df7['Documento'] + df7['Número de posición']\n",
    "\n",
    "# Eliminamos las columnas Documento y Numero de Posición, puesto que no las necesitamos para hacer el BUSCARV\n",
    "df7.drop(['Documento','Número de posición'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd35190",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Busqueda Orden de Servicio y Operacion Orden de Servicio utilizando D+I\n",
    "df6.set_index('D+I', inplace = True)\n",
    "df7.set_index('D+I', inplace = True)\n",
    "df6 = df6.join(df7, how = 'left')\n",
    "df6.sort_values(by = 'Identificador Unico', inplace = True)\n",
    "df6.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4134f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cruce entre nuestro archivo del dia actual con el día anterior usando como valor comun los de 'CONCAT'\n",
    "df10.drop_duplicates(subset = ['CONCAT'], keep = 'first', inplace = True)\n",
    "df10.set_index('CONCAT', inplace = True)\n",
    "df6.set_index('CONCAT', inplace = True)\n",
    "df6 = df6.join(df10, how = 'left')\n",
    "\n",
    "# Ordenamos la data según la columna 'Identificador Unico' que creamos en un principio\n",
    "df6.sort_values(by = 'Identificador Unico', inplace = True)\n",
    "df6.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d94fe311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar Ordenes de Servicio Vacías\n",
    "\n",
    "# Crear Columna Auxiliares\n",
    "df6['Orden de servicio_2'] = df6['Orden de servicio']\n",
    "\n",
    "# Rellenar OS\n",
    "df6.loc[pd.isna(df6['Orden de servicio']), 'Orden de servicio'] = df6.loc[pd.isna(df6['Orden de servicio']), 'OS']\n",
    "\n",
    "# Rellenar OP\n",
    "df6.loc[pd.isna(df6['Orden de servicio_2']), 'Operación de orden de servicio'] =\\\n",
    "df6.loc[pd.isna(df6['Orden de servicio_2']), 'OP']\n",
    "\n",
    "# Eliminar Columna Auxiliar\n",
    "df6.drop(labels = 'Orden de servicio_2' , axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e8c5f57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Eliminamos las columnas que no nos sirven\n",
    "df6.drop(['Identificador Unico', 'OS','OP'], axis = 1, inplace = True)\n",
    "\n",
    "# Renombramos 'Orden de servicio' y 'Operación de orden de servicio' para que tengan el mismo nombre que el archivo original\n",
    "df6.rename({'Orden de servicio': 'OS', 'Operación de orden de servicio' : 'OP'}, axis = 'columns', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f4e4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenamos las columnas para que nos calze con el archivo original\n",
    "column_names_oha = ['OS','OP','TIPO DE PROCESO','Tipo almacén','Ubicación','UMp sup.','UMp superior','Unidad manipulación',\n",
    "                    'Documento','Número de posición','Tipo de documento','Producto','Descripción de producto','Ctd.',\n",
    "                    'Propietario','Persona autorizada a disponer','Fecha EM','Hora EM','Tipo de stocks']\n",
    "\n",
    "df6 = df6.reindex(columns = column_names_oha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c88c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos los 00:00:00 de la columna FECHA EM\n",
    "df6['Fecha EM'] = df6['Fecha EM'].str.replace(\" 00:00:00\",\"\", regex = False)\n",
    "\n",
    "# Colocamos el formato correcto a la columna 'FECHA EM'\n",
    "df6['Fecha EM'] = pd.to_datetime(df6['Fecha EM'])\n",
    "df6['Fecha EM'] = df6['Fecha EM'].dt.strftime(date_format = '%d/%m/%Y')\n",
    "\n",
    "# Formato Correcto Columna Cantidad\n",
    "df6['Ctd.'] = df6['Ctd.'].str.replace(\",\",\".\", regex = False)\n",
    "df6['Ctd.'] = df6['Ctd.'].astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fea63",
   "metadata": {},
   "source": [
    "## Relleno de Celdas Vacías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e929ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los propietarios que no nos interesan = 0. En caso de no tener la Orden de Servicio\n",
    "df6.loc[(pd.isna(df6['OS'])) & ((df6['Propietario'] != 'Y5028') & (df6['Propietario'] != 'Y5082') &\\\n",
    "                                 (df6['Propietario'] != 'Y5099') & (df6['Propietario'] != 'Y5059')), ['OS', 'OP']] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5801e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo el tipo de Proceso 'BLOQUEO' = 0. Se aplica tambien para CSAR/CRE/CRC/KIT\n",
    "df6.loc[(pd.isna(df6['OS'])) & (df6['TIPO DE PROCESO'] == 'BLOQUEO'), ['OS', 'OP']] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48017580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los que no tengan OS, pero cuyo producto empieze con 'SK', le colocamos OS = 0\n",
    "df6.loc[(pd.isna(df6['OS'])) & (df6['Producto'].str.startswith('SK')), ['OS', 'OP']] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a92ff73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS = OP = 0 para la ubicación 9020-STOCKS\n",
    "df6.loc[(pd.isna(df6['OS'])) & (df6['Ubicación'] == '9020-STOCK'), ['OS', 'OP']] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7892c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularización Excedente BO = 0\n",
    "df6.loc[(pd.isna(df6['OS'])) & (df6['Ubicación'] == '0290-EXCEDENTE-BO'), ['OS', 'OP']] = '0'\n",
    "df6.loc[(pd.isna(df6['OS'])) & (df6['Ubicación'] == '8033-EXCEDENTE-BO'), ['OS', 'OP']] = '0'\n",
    "df6.loc[(pd.isna(df6['OS'])) & (df6['Ubicación'] == '9020-EXCEDENTE-BO'), ['OS', 'OP']] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbbae8a",
   "metadata": {},
   "source": [
    "## Arreglos Finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60504bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS y OP que quedaron vacías, las igualamos a #N/A\n",
    "df6.loc[pd.isna(df6['OS']), 'OS'] = '#N/A'\n",
    "df6.loc[pd.isna(df6['OP']), 'OP'] = '#N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0797d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celdas en TIPO DE PROCESO, que quedaron vacías, las igualamos a #N/A\n",
    "df6.loc[pd.isna(df6['TIPO DE PROCESO']), 'TIPO DE PROCESO'] = '#N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad744c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineas en TIPO DE PROCESO = ALMACEN, que no tenga documento asociado, y que tengan OS y OP distinta de cero:\n",
    "# OS = OP = 0\n",
    "df6.loc[(pd.isna(df6['OS']) == False) & (df6['TIPO DE PROCESO'] == 'ALMACEN') & (pd.isna(df6['Documento']) == True) &\\\n",
    "        (df6['OS'] != '0'), ['OS', 'OP']] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3bacd",
   "metadata": {},
   "source": [
    "## Descarga Archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c5400dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descargar Archivos\n",
    "\n",
    "# 17.1 Espacio entre tablas\n",
    "df_base2.rename(columns = {'Unnamed: 2':'', 'Unnamed: 6':''}, inplace = True)\n",
    "\n",
    "# 17.2 Actualizar Nombre Archivo\n",
    "today = date.today()\n",
    "fecha_hoy = today.strftime(\"%Y-%m-%d\")\n",
    "Nombre_Archivo = fecha_hoy + ' ON HAND AVANCE_PG.xlsx'\n",
    "\n",
    "# 17.3 Descargar Archivo\n",
    "with pd.ExcelWriter(Nombre_Archivo) as writer:  \n",
    "    df6.to_excel(writer, sheet_name='BASE 1', index = False)\n",
    "    df_base2.to_excel(writer, sheet_name='BASE 2', index = False)\n",
    "    \n",
    "# 17.4 Abrir Instancia Excel\n",
    "xlApp = win32.Dispatch('Excel.Application')\n",
    "xlApp.Visible = True\n",
    "\n",
    "# 17.5 Abrir On Hand Avance (Libro)\n",
    "path = os.path.abspath(Nombre_Archivo)\n",
    "wb = xlApp.Workbooks.Open(path)\n",
    "\n",
    "# 17.6 Ajustar Columnas\n",
    "wb.Worksheets(1).Activate()\n",
    "wb.ActiveSheet.Columns.AutoFit()\n",
    "\n",
    "wb.Worksheets(2).Activate()\n",
    "wb.ActiveSheet.Columns.AutoFit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6db34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "total_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c44b375e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3701768080393473\n"
     ]
    }
   ],
   "source": [
    "print(total_time / 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
