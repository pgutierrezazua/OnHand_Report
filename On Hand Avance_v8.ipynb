{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424ae41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import win32com.client as win32\n",
    "import os\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212098f8",
   "metadata": {},
   "source": [
    "## Parte 1: Ingreso nombre archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69910735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurso + OnHand\n",
    "r_oh = '2023-09-15 ON HAND AVANCE_PG.xlsx'\n",
    "\n",
    "# 9030 Descarga\n",
    "descarga_9030 = '9030-DESCARGA-15-09-2023.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714c95c8",
   "metadata": {},
   "source": [
    "## Parte 2: Carga archivos + Modificaciones especificas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c2015d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Carga Recurso + OnHand\n",
    "df1 = pd.read_excel(r_oh, sheet_name = 'BASE 1', dtype = 'string', usecols = 'A:S')\n",
    "\n",
    "# 1.1 Al cargar la data, python lee las comas como puntos, por lo tanto aplicamos la funcion replace para mantenerlas como ','\n",
    "df1['Ctd.'] = df1['Ctd.'].str.replace(\".\",\",\", regex = False)\n",
    "\n",
    "# Agregar Columnas TU\n",
    "df1['TU'] = pd.NA\n",
    "df1['FCH. Creacion TU'] = pd.NA\n",
    "df1['CENTRO. SUMNISTRO'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e18ed2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Carga 9030-DESCARGA dia Actual\n",
    "df2 = pd.read_excel(descarga_9030, dtype = 'string',\n",
    "                    usecols = ['Documento','Número de posición','Orden de servicio','Operación de orden de servicio',\n",
    "                              'UMP.SUP','UMP','Prod.','Descripción de producto','Ctd.','Propietario del stock',\n",
    "                              'Status de entrada en stock','Status de la entrada de mercancías',\n",
    "                               'Persona autorizada a disponer', 'TU', 'FCH. Creacion TU', 'CENTRO. SUMNISTRO'])\n",
    "\n",
    "# 2.1 Renombrar las filas del 9030-DESCARGA. \n",
    "df2.rename(columns = {'Orden de servicio':'OS', 'Operación de orden de servicio':'OP', 'UMP.SUP': 'UMp sup.', \n",
    "            'UMP':'Unidad manipulación','Propietario del stock': 'Propietario', 'Status de entrada en stock': 'Fecha EM',\n",
    "          'Status de la entrada de mercancías':'Hora EM','Prod.':'Producto'}, inplace = True)\n",
    "\n",
    "# 2.2 Creamos las columnas CONCAT y D+I, al igual que el archivo OnHand Avance.\n",
    "df2['CONCAT'] = df2['Unidad manipulación'] + df2['Producto'] + df2['Ctd.']\n",
    "df2['D+I'] = df2['Documento'] + df2['Número de posición']\n",
    "\n",
    "# 2.3 Agregar columnas en archivo 9030-DESCARGA, para así poder realizar concatenado con Recurso+OnHand\n",
    "df2['Revi'], df2['TP.UBI'], df2['OS+OP+MAT+CDT'], df2['OS+OP+MAT'], df2['OS.SUP'], df2['OSO'], df2['TIPO DE PROCESO'], \\\n",
    "df2['Tipo almacén'], df2['Ubicación'], df2['UMp superior'], df2['Tipo de documento'] = ['', pd.NA, '', '', '', '', 'DESCARGA', \n",
    "                                                                                        '9030', '9030-DESCARGA', '','PDI']\n",
    "\n",
    "# 2.4 Reordenamos las columnas para que sean igual al orden de Recurso+OnHand\n",
    "df2 = df2.reindex(columns = df1.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6b9de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pablo.gutierrez\\AppData\\Local\\Temp\\ipykernel_7440\\28481621.py:16: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df2.loc[pd.isna(df2['Fecha EM']) == True, 'Fecha EM'] = df2['Fecha EM_Aux'].iloc[df2.loc[pd.isna(df2['Fecha EM'])].index.values]\n"
     ]
    }
   ],
   "source": [
    "# 3. Arreglo Formato Fecha para que quede como texto\n",
    "\n",
    "# 3.1 Eliminar '00:00:00'\n",
    "df2['Fecha EM'] = df2['Fecha EM'].str.replace(\" 00:00:00\",\"\", regex = False)\n",
    "\n",
    "# 3.2 Crear Columna Auxiliar\n",
    "df2['Fecha EM_Aux'] = df2['Fecha EM']\n",
    "\n",
    "# 3.3 Fecha EM a formato a Datetime\n",
    "df2['Fecha EM'] = pd.to_datetime(df2['Fecha EM'], errors = 'coerce', format = \"%Y/%m/%d\", yearfirst = True)\n",
    "\n",
    "# 3.4 Fecha EM a String\n",
    "df2['Fecha EM'] = df2['Fecha EM'].dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "# 3.5 Aquellos que no tenian formato fecha , los igualamos a la columna Auxiliar para recuperar dichos valores\n",
    "df2.loc[pd.isna(df2['Fecha EM']) == True, 'Fecha EM'] = df2['Fecha EM_Aux'].iloc[df2.loc[pd.isna(df2['Fecha EM'])].index.values]\n",
    "\n",
    "# 3.6 Borrar Fecha Auxiliar\n",
    "df2.drop(labels = 'Fecha EM_Aux', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86224082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Cargar BASE 2 On Hand Avance (Toda la hoja)\n",
    "df_base2 = pd.read_excel(r_oh, sheet_name = 'BASE 2', dtype = 'string')\n",
    "df4 = df_base2.loc[: , ['UBICACIÓN','OBSERVACION']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb442b76",
   "metadata": {},
   "source": [
    "## Parte 3: Modificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9681d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Concatenar\n",
    "\n",
    "# 5.1 Unir OHA_PG y 9030D\n",
    "df3 = pd.concat([df1,df2], axis = 0)\n",
    "\n",
    "# 5.2 Reset Index y eliminar columna index\n",
    "df3.reset_index(inplace = True)\n",
    "df3.drop(columns = 'index', axis = 1, inplace = True)\n",
    "\n",
    "# 5.3 Agregamos identificador unico\n",
    "df3['Identificador Unico'] = df3.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66af0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Si OS = 'Revisado', Entonces OS = OP = 0\n",
    "df3.loc[df3['OS'] == 'REVISADO', 'OS'] = '0'\n",
    "df3.loc[df3['OS'] == 'REVISADO', 'OP'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "637d6aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pablo.gutierrez\\AppData\\Local\\Temp\\ipykernel_7440\\4266819642.py:2: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  df3.loc[: , 'OP'] = list(map(lambda x: x.zfill(4), df3['OP']))\n"
     ]
    }
   ],
   "source": [
    "# 7. Aplicamos función TEXTO a la Operación\n",
    "df3.loc[: , 'OP'] = list(map(lambda x: x.zfill(4), df3['OP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395c10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Creamos las columnas nuevas\n",
    "df3.loc[pd.isna(df3['Unidad manipulación']), 'Unidad manipulación'] = ''\n",
    "df3['CONCAT'] = df3['Unidad manipulación'] + df3['Producto'] + df3['Ctd.']\n",
    "df3['OSO'] = df3['OS'] + df3['OP']\n",
    "df3['OS.SUP'] = [i[:10] + '00' for i in df3['OS']]\n",
    "df3['OS+OP+MAT'] = df3['OS'] + df3['OP'] + df3['Producto']\n",
    "df3['OS+OP+MAT+CDT'] = df3['OS'] + df3['OP'] + df3['Producto'] + df3['Ctd.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a158b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Si la ubicación contiene Excedente, Faltante o Sobrante, entonces de OSOPMATCTD a OP = 0\n",
    "df3.loc[df3['Ubicación'].str.contains('EXCEDENTE'), ['OS', 'OP', 'OSO', 'OS.SUP', 'OS+OP+MAT', 'OS+OP+MAT+CDT']] = '0'\n",
    "df3.loc[df3['Ubicación'].str.contains('FALTANTE'), ['OS', 'OP', 'OSO', 'OS.SUP', 'OS+OP+MAT', 'OS+OP+MAT+CDT']] = '0'\n",
    "df3.loc[df3['Ubicación'].str.contains('SOBRANTE'), ['OS', 'OP', 'OSO', 'OS.SUP', 'OS+OP+MAT', 'OS+OP+MAT+CDT']] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e1820f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 10. Cruce ELIMINAR OS\n",
    "\n",
    "# 10.1 Eliminar Duplicados columna Ubicación Base 2\n",
    "df4.drop_duplicates(subset = 'UBICACIÓN', inplace = True)\n",
    "\n",
    "# 10.2 Definir Key values para realizar el Join. En este caso, el valor común entre ambas columnas es la Ubicación\n",
    "df3.set_index('Ubicación', inplace = True)\n",
    "df4.set_index('UBICACIÓN', inplace = True)\n",
    "\n",
    "# 10.3 Join (BUSCARV en excel)\n",
    "df5 = df3.join(df4, how = 'left')\n",
    "\n",
    "# 10.4 Ordenamos la data según la columna 'Identificador Unico' que creamos en un principio\n",
    "df5.sort_values(by = 'Identificador Unico', inplace = True)\n",
    "\n",
    "# 10.5 Reset index\n",
    "df5.reset_index(inplace = True)\n",
    "\n",
    "# 10.6 Columna Ubicación a su posicion Original\n",
    "index = df5.pop('index')\n",
    "df5.insert(loc = 12, column = 'Ubicación', value = index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98a2ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Cruce con Base 2 para dejar OSOPMAT = 0 aquellos que nos arroje el\n",
    "\n",
    "# 11.1 Rellenar con NO ELIMINAR aquellas celdas NA del Join\n",
    "df5['OBSERVACION'].fillna('NO ELIMINAR', inplace = True)\n",
    "\n",
    "# 11.2 Si OBSERVACION = ElIMINAR OS, OS+OP+MAT = 0\n",
    "df5.loc[df5['OBSERVACION'] == 'ELIMINAR OS', 'OS+OP+MAT'] = '0'\n",
    "\n",
    "# 11.3 Eliminamos la columna Observación\n",
    "df5.drop(columns = 'OBSERVACION', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cde86471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Para todo 'OS' = 0\n",
    "df5.loc[df5['OS'] == '0' , ['OP', 'OSO', 'OS.SUP', 'OS+OP+MAT', 'OS+OP+MAT+CDT']] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0351eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Formato Correcto Columna Cantidad\n",
    "df5['Ctd.'] = df5['Ctd.'].str.replace(\",\",\".\", regex = False)\n",
    "df5['Ctd.'] = df5['Ctd.'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f00c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Ordenamos la data según la columna 'Identificador Unico' que creamos en un principio\n",
    "df5.sort_values(by = 'Identificador Unico', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e152971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Rellenar Columna TP.UBI \n",
    "\n",
    "# 15.1 TP UBI 8034\n",
    "df5.loc[df5['Tipo almacén'] == '8032', 'TP.UBI'] = '8034'\n",
    "df5.loc[df5['Tipo almacén'] == '8034', 'TP.UBI'] = '8034'\n",
    "df5.loc[df5['Ubicación'].str.contains('9020-CRC'), 'TP.UBI'] = '8034'\n",
    "df5.loc[df5['Ubicación'].str.contains('9020-REGUL-CRC'), 'TP.UBI'] = '8034'\n",
    "df5.loc[df5['Ubicación'].str.contains('9020-SUBKIT'), 'TP.UBI'] = '8034'\n",
    "\n",
    "# 15.2 TP.UBI OTROS\n",
    "df5.loc[(pd.isna(df5['TP.UBI']) == True), 'TP.UBI'] = 'OTROS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8fc9717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orden final de columnas\n",
    "df5 = df5[['CONCAT','TP.UBI','OS+OP+MAT+CDT','OS+OP+MAT','OS.SUP','OSO','OS','OP','TIPO DE PROCESO',\n",
    "        'Tipo almacén','Ubicación','UMp sup.','UMp superior','Unidad manipulación','Documento','Número de posición',\n",
    "        'Tipo de documento','Producto','Descripción de producto','Ctd.','Propietario','Persona autorizada a disponer',\n",
    "        'Fecha EM','Hora EM','Tipo de stocks','TU','FCH. Creacion TU','CENTRO. SUMNISTRO']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82baf2d5",
   "metadata": {},
   "source": [
    "## Formato Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "123af488",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Espacio entre tablas\n",
    "df_base2.rename(columns = {'Unnamed: 2':'', 'Unnamed: 6':''}, inplace = True)\n",
    "\n",
    "# Actualizar Nombre Archivo\n",
    "today = date.today()\n",
    "fecha_hoy = today.strftime(\"%Y-%m-%d\")\n",
    "Nombre_Archivo = fecha_hoy + ' ON HAND AVANCE.xlsx'\n",
    "\n",
    "# Descargar Archivo\n",
    "with pd.ExcelWriter(Nombre_Archivo) as writer:  \n",
    "    df5.to_excel(writer, sheet_name='BASE 1', index = False)\n",
    "    df_base2.to_excel(writer, sheet_name='BASE 2', index = False)\n",
    "    \n",
    "# Abrir Instancia Excel\n",
    "xlApp = win32.Dispatch('Excel.Application')\n",
    "xlApp.Visible = True\n",
    "\n",
    "# Abrir On Hand Avance (Libro)\n",
    "path = os.path.abspath(Nombre_Archivo)\n",
    "wb = xlApp.Workbooks.Open(path)\n",
    "\n",
    "# Ajustar Columnas\n",
    "wb.Worksheets(1).Activate()\n",
    "wb.ActiveSheet.Columns.AutoFit()\n",
    "\n",
    "wb.Worksheets(2).Activate()\n",
    "wb.ActiveSheet.Columns.AutoFit()\n",
    "\n",
    "# Eliminar Columnas Inncesarias BASE 1\n",
    "wb.Worksheets(1).Activate()\n",
    "wb.ActiveSheet.Columns('A:D').Delete()\n",
    "\n",
    "# Guardar como XLSB\n",
    "wb.SaveAs(Filename = os.path.dirname(path) + '\\\\' + fecha_hoy + ' ON HAND AVANCE', FileFormat = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b852b36",
   "metadata": {},
   "source": [
    "## Busqueda OS para obtener Activación y QPLUSS ECC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91dbfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18.1 Insertar Columna Plan\n",
    "df5.insert(column = 'Plan', loc = 26, value = pd.NA)\n",
    "\n",
    "# 18.2 Crear Columnas auxiliares 4 primeros digitos y 6 primeros digitos\n",
    "df5['OS.SUP_AUX'] = list(map(lambda x: x[:4], df5['OS.SUP']))\n",
    "df5['OS.SUP_KIT'] = list(map(lambda x: x[:6], df5['OS.SUP']))\n",
    "\n",
    "# 18.3 Replacements\n",
    "df5.loc[df5['OS.SUP_AUX'] == '5028', 'Plan'] = 'PLAN CSAR'\n",
    "df5.loc[df5['OS.SUP_AUX'] == '5082', 'Plan'] = 'PLAN CRE'\n",
    "df5.loc[df5['OS.SUP_AUX'] == '5059', 'Plan'] = 'PLAN CRC'\n",
    "df5.loc[df5['OS.SUP_KIT'] == '000001', 'Plan'] = 'PLAN KIT'\n",
    "df5.loc[(pd.isna(df5['Plan'])) == True , 'Plan'] = pd.NA\n",
    "\n",
    "# 18.4 Eliminar Columnas Auxiliares\n",
    "df5.drop(labels = ['OS.SUP_AUX', 'OS.SUP_KIT'], axis = 1, inplace = True)\n",
    "\n",
    "# 18.5 Columna OS solo con los Clientes de Interés\n",
    "busqueda_os = df5.loc[pd.isna(df5['Plan']) == False, 'OS']\n",
    "busqueda_os = pd.DataFrame({'QPLUSS ECC' : busqueda_os.values})\n",
    "\n",
    "# 18.6 ELiminar Duplicados\n",
    "busqueda_os.drop_duplicates(keep = 'first', inplace = True)\n",
    "\n",
    "# 18.7 OS.SUP para busqueda ACTIVACIÓN\n",
    "busqueda_os['ACTIVACIÓN'] = [i[:10] + '*' for i in busqueda_os['QPLUSS ECC']]\n",
    "\n",
    "# 18.8 Descargar Archivo\n",
    "busqueda_os.to_excel('Busqueda_Activación_QPLUSSECC.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdd41e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo Total: 2.60 minutos\n"
     ]
    }
   ],
   "source": [
    "# 17. Calculo Tiempo Procesamiento\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_time = total_time / 60\n",
    "total_time = \"{:.2f}\".format(total_time)\n",
    "total_time = str(total_time)\n",
    "print('Tiempo Total: ' + total_time + ' minutos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b475fbec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
